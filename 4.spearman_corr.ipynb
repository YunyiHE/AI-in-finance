{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "import keras.backend as K\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see how to calculate the spearman correlation using numpy (1a), tensors (1b) and scipy.stats.spearmanr (3).\n",
    "The results are similar. The comparison is in 3.\n",
    "See: https://archive.md/VfNkG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy spearman: 0.19999999999999993\n",
      "tf spearman 0.2\n",
      "SpearmanrResult(correlation=0.19999999999999998, pvalue=0.747060078104662)\n"
     ]
    }
   ],
   "source": [
    "#1a spearman from scratch using numpy\n",
    "def spearman_correlation(predictions, targets):\n",
    "    if not isinstance(predictions, pd.Series):\n",
    "        predictions = pd.Series(predictions)\n",
    "    ranked_preds = predictions.rank(pct = True, method = \"first\")\n",
    "    return np.corrcoef(ranked_preds, targets)[0, 1]\n",
    "\n",
    "#2a spearman from scratch using tensors\n",
    "def corrcoef(x, y):\n",
    "\n",
    "    mx = tf.math.reduce_mean(x)\n",
    "    my = tf.math.reduce_mean(y)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = tf.math.reduce_sum(xm * ym)\n",
    "    r_den = tf.norm(xm) * tf.norm(ym)\n",
    "    return r_num / (r_den + tf.keras.backend.epsilon())\n",
    "\n",
    "#2b. spearman using tensors\n",
    "def tf_spearman_correlation(predictions, targets):\n",
    "    ranked_preds = tf.cast(tf.argsort(tf.argsort(predictions, stable = True)), targets.dtype)\n",
    "    return corrcoef(ranked_preds, targets)\n",
    "\n",
    "targets = np.array([0.0, 0.25, 0.5, 0.75, 1.0], dtype = np.float32)\n",
    "predictions = np.random.rand(targets.shape[0])\n",
    "\n",
    "print(\"numpy spearman:\", spearman_correlation(predictions, targets))\n",
    "result = tf_spearman_correlation(tf.convert_to_tensor(predictions, dtype=tf.float32), tf.convert_to_tensor(targets, dtype=tf.float32))\n",
    "with tf.Session() as sess:\n",
    "    scalar = result.eval()\n",
    "\n",
    "    \n",
    "#COMPARISON\n",
    "\n",
    "print(\"tf spearman\", scalar)\n",
    "#3\n",
    "print (spearmanr(targets,predictions))  #spearman using scipy stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use tensors to program a spearman loss. Note the argsort operation in line 7, which is not differentiable. \n",
    "If you tell Keras to use this spearman_loss, it will complain about the lack of a gradient. So spearman_loss cannot be used.  The ranking step needs to substituted by a tensor operation that is similar enough and yet differentiable not available in tf 1.5.\n",
    "IMPORTANT: in any case, if you want to use spearman_loss you want to use penalized_pearson_loss to make sure that it converges with the mse (see 5.pearson_corr.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_loss(y_true, y_pred, axis=-2):\n",
    "#Generates an error due to ranking operation not being differentiable do not use\n",
    "    \"\"\"Spearman correlation coefficient using tensors\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    y = tf.cast(tf.argsort(tf.argsort(y, stable = True)), targets.dtype) #argsort is not a differentiable operation\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "    \n",
    "    ysqsum = K.sum(K.square(ym))\n",
    "    n = tf.cast(tf.shape(x)[axis], x.dtype)\n",
    "    sqdif = tf.reduce_sum(tf.math.squared_difference(x, y), axis=axis) / n / tf.sqrt(ysqsum / n)\n",
    "\n",
    "    return  tf.convert_to_tensor(tf.constant(1.0, dtype=x.dtype) - K.square(r)  + (0.01 * sqdif))\n",
    "\n",
    "def penalized_spearman_loss(x,y, axis=-2):\n",
    "    \"\"\"Penalized Spearman correlation coefficient\"\"\"\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    y = tf.cast(tf.argsort(tf.argsort(y, stable = True)), targets.dtype) #argsort is not a differentiable operation\n",
    "    #y = K.cast(y, x.dtype)\n",
    "    n = tf.cast(tf.shape(x)[axis], x.dtype)\n",
    "    xsum = tf.reduce_sum(x, axis=axis)\n",
    "    ysum = tf.reduce_sum(y, axis=axis)\n",
    "    xmean = xsum / n\n",
    "    ymean = ysum / n\n",
    "    xsqsum = tf.reduce_sum( tf.math.squared_difference(x, xmean), axis=axis)\n",
    "    ysqsum = tf.reduce_sum( tf.math.squared_difference(y, ymean), axis=axis)\n",
    "    cov = tf.reduce_sum( (x - xmean) * (y - ymean), axis=axis)\n",
    "    corr = cov / (tf.sqrt(xsqsum * ysqsum)+ K.epsilon())\n",
    "    sqdif = tf.reduce_sum(tf.math.squared_difference(x, y), axis=axis) / n / tf.sqrt(ysqsum / n)\n",
    "    return tf.convert_to_tensor( K.mean(tf.constant(1.0, dtype=x.dtype) - corr + (0.01 * sqdif)) , dtype=tf.float32 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use tensors to program a spearman metric. Note the use of py_func (a shortcut)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "py_func is a tf wrapper for a python function. py_func returns a tensor.\n",
    "Below we use py_func to wrap around the python function spearmanr.\n",
    "This use of py_func works in my setup but it does not always work.\n",
    "If you have problems with it, \n",
    "just use the spearman_metric underneath (commented out) that uses tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman_metric(y_true, y_pred):\n",
    "    \"\"\"Spearman correlation coefficient using a tf wrapper for a python function\"\"\"\n",
    "\n",
    "    r = tf.py_function(spearmanr, inp=[y_true, y_pred], Tout=tf.float32)\n",
    "    \n",
    "    return  tf.constant(1.0, dtype=y_true.dtype) - r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def spearman_metric(y_true, y_pred):\n",
    "    \"\"\"Spearman correlation coefficient using tensors\"\"\"\n",
    "\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    y = tf.cast(tf.argsort(tf.argsort(y, stable = True)), targets.dtype)\n",
    "    xm, ym = x - K.mean(x), y - K.mean(y)\n",
    "    r_num = K.sum(tf.multiply(xm, ym))\n",
    "    r_den = K.sqrt(tf.multiply(K.sum(K.square(xm)), K.sum(K.square(ym))))\n",
    "    r = r_num / (r_den + K.epsilon())\n",
    "    r = K.maximum(K.minimum(r, 1.0), -1.0)\n",
    "\n",
    "    return  tf.constant(1.0, dtype=x.dtype) - K.square(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=num_features, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainX)\n",
    "# transform training dataset\n",
    "trainX = scaler.transform(trainX)\n",
    "# transform test dataset\n",
    "testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 582us/step - loss: 1.4626 - spearman_metric: 0.8298 - val_loss: 0.6984 - val_spearman_metric: 0.3483\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 132us/step - loss: 0.3686 - spearman_metric: 0.2206 - val_loss: 0.2664 - val_spearman_metric: 0.1081\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.1954 - spearman_metric: 0.1091 - val_loss: 0.1742 - val_spearman_metric: 0.0771\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.1227 - spearman_metric: 0.0755 - val_loss: 0.1404 - val_spearman_metric: 0.0632\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0950 - spearman_metric: 0.0554 - val_loss: 0.1320 - val_spearman_metric: 0.0502\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0807 - spearman_metric: 0.0460 - val_loss: 0.1077 - val_spearman_metric: 0.0489\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0700 - spearman_metric: 0.0433 - val_loss: 0.1047 - val_spearman_metric: 0.0463\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0622 - spearman_metric: 0.0444 - val_loss: 0.0891 - val_spearman_metric: 0.0418\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0525 - spearman_metric: 0.0398 - val_loss: 0.0830 - val_spearman_metric: 0.0399\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0469 - spearman_metric: 0.0341 - val_loss: 0.0767 - val_spearman_metric: 0.0370\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0417 - spearman_metric: 0.0312 - val_loss: 0.0727 - val_spearman_metric: 0.0348\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0398 - spearman_metric: 0.0295 - val_loss: 0.0749 - val_spearman_metric: 0.0331\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0379 - spearman_metric: 0.0265 - val_loss: 0.0659 - val_spearman_metric: 0.0318\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0343 - spearman_metric: 0.0251 - val_loss: 0.0575 - val_spearman_metric: 0.0309\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0298 - spearman_metric: 0.0229 - val_loss: 0.0558 - val_spearman_metric: 0.0303\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0279 - spearman_metric: 0.0242 - val_loss: 0.0521 - val_spearman_metric: 0.0279\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0260 - spearman_metric: 0.0187 - val_loss: 0.0499 - val_spearman_metric: 0.0277\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0246 - spearman_metric: 0.0222 - val_loss: 0.0502 - val_spearman_metric: 0.0265\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0244 - spearman_metric: 0.0198 - val_loss: 0.0453 - val_spearman_metric: 0.0257\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0215 - spearman_metric: 0.0193 - val_loss: 0.0433 - val_spearman_metric: 0.0247\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0201 - spearman_metric: 0.0173 - val_loss: 0.0405 - val_spearman_metric: 0.0229\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0199 - spearman_metric: 0.0222 - val_loss: 0.0406 - val_spearman_metric: 0.0222\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0182 - spearman_metric: 0.0178 - val_loss: 0.0394 - val_spearman_metric: 0.0226\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0177 - spearman_metric: 0.0146 - val_loss: 0.0370 - val_spearman_metric: 0.0224\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0167 - spearman_metric: 0.0172 - val_loss: 0.0364 - val_spearman_metric: 0.0224\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0161 - spearman_metric: 0.0163 - val_loss: 0.0343 - val_spearman_metric: 0.0210\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0155 - spearman_metric: 0.0148 - val_loss: 0.0332 - val_spearman_metric: 0.0206\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0146 - spearman_metric: 0.0157 - val_loss: 0.0315 - val_spearman_metric: 0.0201\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0137 - spearman_metric: 0.0138 - val_loss: 0.0316 - val_spearman_metric: 0.0207\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0133 - spearman_metric: 0.0123 - val_loss: 0.0304 - val_spearman_metric: 0.0198\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0129 - spearman_metric: 0.0127 - val_loss: 0.0286 - val_spearman_metric: 0.0195\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0122 - spearman_metric: 0.0132 - val_loss: 0.0279 - val_spearman_metric: 0.0185\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0122 - spearman_metric: 0.0116 - val_loss: 0.0284 - val_spearman_metric: 0.0191\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0120 - spearman_metric: 0.0139 - val_loss: 0.0262 - val_spearman_metric: 0.0180\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0112 - spearman_metric: 0.0102 - val_loss: 0.0268 - val_spearman_metric: 0.0189\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 91us/step - loss: 0.0116 - spearman_metric: 0.0112 - val_loss: 0.0256 - val_spearman_metric: 0.0174\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 91us/step - loss: 0.0108 - spearman_metric: 0.0112 - val_loss: 0.0248 - val_spearman_metric: 0.0174\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0105 - spearman_metric: 0.0122 - val_loss: 0.0260 - val_spearman_metric: 0.0169\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0109 - spearman_metric: 0.0109 - val_loss: 0.0240 - val_spearman_metric: 0.0169\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 102us/step - loss: 0.0097 - spearman_metric: 0.0101 - val_loss: 0.0234 - val_spearman_metric: 0.0172\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0096 - spearman_metric: 0.0104 - val_loss: 0.0240 - val_spearman_metric: 0.0170\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0092 - spearman_metric: 0.0087 - val_loss: 0.0223 - val_spearman_metric: 0.0164\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0091 - spearman_metric: 0.0095 - val_loss: 0.0223 - val_spearman_metric: 0.0167\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0089 - spearman_metric: 0.0097 - val_loss: 0.0216 - val_spearman_metric: 0.0164\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0086 - spearman_metric: 0.0089 - val_loss: 0.0217 - val_spearman_metric: 0.0158\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0085 - spearman_metric: 0.0100 - val_loss: 0.0214 - val_spearman_metric: 0.0156\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0086 - spearman_metric: 0.0099 - val_loss: 0.0202 - val_spearman_metric: 0.0154\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0080 - spearman_metric: 0.0099 - val_loss: 0.0200 - val_spearman_metric: 0.0151\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0086 - spearman_metric: 0.0072 - val_loss: 0.0204 - val_spearman_metric: 0.0156\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0089 - spearman_metric: 0.0077 - val_loss: 0.0199 - val_spearman_metric: 0.0147\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0077 - spearman_metric: 0.0067 - val_loss: 0.0188 - val_spearman_metric: 0.0142\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0076 - spearman_metric: 0.0080 - val_loss: 0.0190 - val_spearman_metric: 0.0145\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0073 - spearman_metric: 0.0086 - val_loss: 0.0189 - val_spearman_metric: 0.0141\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0070 - spearman_metric: 0.0074 - val_loss: 0.0182 - val_spearman_metric: 0.0142\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0071 - spearman_metric: 0.0098 - val_loss: 0.0183 - val_spearman_metric: 0.0139\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 95us/step - loss: 0.0068 - spearman_metric: 0.0066 - val_loss: 0.0174 - val_spearman_metric: 0.0135\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0066 - spearman_metric: 0.0083 - val_loss: 0.0174 - val_spearman_metric: 0.0140\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0066 - spearman_metric: 0.0089 - val_loss: 0.0179 - val_spearman_metric: 0.0134\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 100us/step - loss: 0.0069 - spearman_metric: 0.0077 - val_loss: 0.0175 - val_spearman_metric: 0.0132\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0065 - spearman_metric: 0.0080 - val_loss: 0.0173 - val_spearman_metric: 0.0133\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0065 - spearman_metric: 0.0073 - val_loss: 0.0166 - val_spearman_metric: 0.0130\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0060 - spearman_metric: 0.0073 - val_loss: 0.0164 - val_spearman_metric: 0.0130\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0060 - spearman_metric: 0.0080 - val_loss: 0.0163 - val_spearman_metric: 0.0131\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0061 - spearman_metric: 0.0070 - val_loss: 0.0161 - val_spearman_metric: 0.0125\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0058 - spearman_metric: 0.0079 - val_loss: 0.0163 - val_spearman_metric: 0.0131\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0057 - spearman_metric: 0.0064 - val_loss: 0.0155 - val_spearman_metric: 0.0124\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0057 - spearman_metric: 0.0071 - val_loss: 0.0154 - val_spearman_metric: 0.0125\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0057 - spearman_metric: 0.0069 - val_loss: 0.0157 - val_spearman_metric: 0.0125\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0056 - spearman_metric: 0.0070 - val_loss: 0.0148 - val_spearman_metric: 0.0123\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0059 - spearman_metric: 0.0056 - val_loss: 0.0161 - val_spearman_metric: 0.0126\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0056 - spearman_metric: 0.0069 - val_loss: 0.0151 - val_spearman_metric: 0.0124\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 95us/step - loss: 0.0054 - spearman_metric: 0.0061 - val_loss: 0.0145 - val_spearman_metric: 0.0123\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0052 - spearman_metric: 0.0073 - val_loss: 0.0149 - val_spearman_metric: 0.0124\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0052 - spearman_metric: 0.0077 - val_loss: 0.0143 - val_spearman_metric: 0.0119\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0052 - spearman_metric: 0.0073 - val_loss: 0.0150 - val_spearman_metric: 0.0125\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0052 - spearman_metric: 0.0064 - val_loss: 0.0144 - val_spearman_metric: 0.0120\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0052 - spearman_metric: 0.0068 - val_loss: 0.0146 - val_spearman_metric: 0.0123\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0050 - spearman_metric: 0.0069 - val_loss: 0.0139 - val_spearman_metric: 0.0119\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0049 - spearman_metric: 0.0056 - val_loss: 0.0138 - val_spearman_metric: 0.0118\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0048 - spearman_metric: 0.0064 - val_loss: 0.0141 - val_spearman_metric: 0.0118\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0047 - spearman_metric: 0.0061 - val_loss: 0.0137 - val_spearman_metric: 0.0120\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0047 - spearman_metric: 0.0051 - val_loss: 0.0137 - val_spearman_metric: 0.0116\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0046 - spearman_metric: 0.0055 - val_loss: 0.0138 - val_spearman_metric: 0.0117\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0045 - spearman_metric: 0.0056 - val_loss: 0.0144 - val_spearman_metric: 0.0119\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0046 - spearman_metric: 0.0068 - val_loss: 0.0131 - val_spearman_metric: 0.0116\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0045 - spearman_metric: 0.0055 - val_loss: 0.0132 - val_spearman_metric: 0.0113\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0044 - spearman_metric: 0.0073 - val_loss: 0.0128 - val_spearman_metric: 0.0114\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0044 - spearman_metric: 0.0055 - val_loss: 0.0135 - val_spearman_metric: 0.0115\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0043 - spearman_metric: 0.0046 - val_loss: 0.0132 - val_spearman_metric: 0.0114\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0043 - spearman_metric: 0.0055 - val_loss: 0.0132 - val_spearman_metric: 0.0111\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 98us/step - loss: 0.0043 - spearman_metric: 0.0053 - val_loss: 0.0127 - val_spearman_metric: 0.0111\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0042 - spearman_metric: 0.0047 - val_loss: 0.0127 - val_spearman_metric: 0.0111\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0041 - spearman_metric: 0.0052 - val_loss: 0.0125 - val_spearman_metric: 0.0112\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 99us/step - loss: 0.0044 - spearman_metric: 0.0072 - val_loss: 0.0127 - val_spearman_metric: 0.0106\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0045 - spearman_metric: 0.0056 - val_loss: 0.0125 - val_spearman_metric: 0.0113\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 94us/step - loss: 0.0043 - spearman_metric: 0.0051 - val_loss: 0.0126 - val_spearman_metric: 0.0110\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 92us/step - loss: 0.0039 - spearman_metric: 0.0050 - val_loss: 0.0125 - val_spearman_metric: 0.0104\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 93us/step - loss: 0.0039 - spearman_metric: 0.0042 - val_loss: 0.0123 - val_spearman_metric: 0.0110\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 97us/step - loss: 0.0038 - spearman_metric: 0.0047 - val_loss: 0.0120 - val_spearman_metric: 0.0108\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 96us/step - loss: 0.0039 - spearman_metric: 0.0045 - val_loss: 0.0120 - val_spearman_metric: 0.0104\n",
      "500/500 [==============================] - 0s 50us/step\n",
      "500/500 [==============================] - 0s 44us/step\n",
      "Train loss: 0.004, Test loss: 0.012\n",
      "Train metric: 0.004, Test metric: 0.010\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mlp with scaled outputs on the regression problem with custom loss and custom metric\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model using as loss: 'mean_squared_error', and as metric: spearman_metric\n",
    "#model.compile(loss=spearman_loss, optimizer=SGD(lr=0.01, momentum=0.9), metrics=[spearman_metric]) #no gradient for spearman_loss, cannot use\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9), metrics=[spearman_metric])\n",
    "#model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9))\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=1)\n",
    "# evaluate the model\n",
    "train_e = model.evaluate(trainX, trainy, verbose=1)\n",
    "test_e = model.evaluate(testX, testy, verbose=1)\n",
    "print('Train loss: %.3f, Test loss: %.3f' % (train_e[0], test_e[0])) #when using custom loss and custom metric\n",
    "print('Train metric: %.3f, Test metric: %.3f' % (train_e[1], test_e[1])) #when using custom loss and custom metric\n",
    "#print('Train loss: %.3f, Test loss: %.3f' % (train_e, test_e)) \n",
    "#plot loss during training\n",
    "pyplot.title('Loss / Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does Keras use metric functions (including custom metric functions) for anything other than reporting?\n",
    "You can use a metric function in a callback to make Keras stop training when the metric function's score\n",
    "is no longer improving.\n",
    "See:\n",
    "https://archive.md/OLvkZ\n",
    "https://archive.md/VTS87\n",
    "https://archive.md/RV8A8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
