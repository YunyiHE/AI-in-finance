{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=num_features, noise=0.1, random_state=1)\n",
    "\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainX)\n",
    "# transform training dataset\n",
    "trainX = scaler.transform(trainX)\n",
    "# transform test dataset\n",
    "testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(trainy, columns=['y'])\n",
    "df['lab']=np.where(df.y.shift(-1)>df.y,1,0) #like price prediction\n",
    "trainy=df.lab.fillna(0).values\n",
    "df = pd.DataFrame(testy, columns=['y'])\n",
    "df['lab']=np.where(df.y.shift(-1)>df.y,1,0) #like price prediction\n",
    "testy=df.lab.fillna(0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 0s 339us/step - loss: 0.9822 - acc: 0.6140 - val_loss: 0.7109 - val_acc: 0.5960\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7202 - acc: 0.625 - 0s 42us/step - loss: 0.7317 - acc: 0.5880 - val_loss: 0.6819 - val_acc: 0.6740\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.6836 - acc: 0.7160 - val_loss: 0.6826 - val_acc: 0.6940\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.6776 - acc: 0.7400 - val_loss: 0.6776 - val_acc: 0.7040\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6767 - acc: 0.7320 - val_loss: 0.6793 - val_acc: 0.6800\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6770 - acc: 0.6940 - val_loss: 0.6793 - val_acc: 0.6740\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6773 - acc: 0.6820 - val_loss: 0.6789 - val_acc: 0.6660\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.6765 - acc: 0.6800 - val_loss: 0.6798 - val_acc: 0.6720\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.6775 - acc: 0.6660 - val_loss: 0.6794 - val_acc: 0.6340\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.6771 - acc: 0.6740 - val_loss: 0.6769 - val_acc: 0.6800\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6767 - acc: 0.6880 - val_loss: 0.6813 - val_acc: 0.6520\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6775 - acc: 0.6860 - val_loss: 0.6789 - val_acc: 0.6500\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6770 - acc: 0.7040 - val_loss: 0.6783 - val_acc: 0.6820\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.6766 - acc: 0.7080 - val_loss: 0.6801 - val_acc: 0.6540\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6778 - acc: 0.6820 - val_loss: 0.6774 - val_acc: 0.6680\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6780 - acc: 0.6840 - val_loss: 0.6811 - val_acc: 0.6560\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6783 - acc: 0.6740 - val_loss: 0.6788 - val_acc: 0.6660\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6775 - acc: 0.6600 - val_loss: 0.6794 - val_acc: 0.6320\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.6777 - acc: 0.6980 - val_loss: 0.6782 - val_acc: 0.6720\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6768 - acc: 0.6800 - val_loss: 0.6803 - val_acc: 0.6240\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6765 - acc: 0.6840 - val_loss: 0.6810 - val_acc: 0.6640\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6769 - acc: 0.6880 - val_loss: 0.6788 - val_acc: 0.6540\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6765 - acc: 0.6760 - val_loss: 0.6792 - val_acc: 0.6500\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6781 - acc: 0.6880 - val_loss: 0.6794 - val_acc: 0.6640\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6776 - acc: 0.7040 - val_loss: 0.6796 - val_acc: 0.6660\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6780 - acc: 0.6780 - val_loss: 0.6779 - val_acc: 0.6700\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6768 - acc: 0.6860 - val_loss: 0.6785 - val_acc: 0.6800\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6764 - acc: 0.7120 - val_loss: 0.6797 - val_acc: 0.6700\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6758 - acc: 0.6760 - val_loss: 0.6786 - val_acc: 0.6440\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6766 - acc: 0.6880 - val_loss: 0.6793 - val_acc: 0.6560\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6764 - acc: 0.6940 - val_loss: 0.6795 - val_acc: 0.6480\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6770 - acc: 0.6820 - val_loss: 0.6803 - val_acc: 0.6380\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6780 - acc: 0.6940 - val_loss: 0.6776 - val_acc: 0.6600\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.6768 - acc: 0.7140 - val_loss: 0.6787 - val_acc: 0.6680\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6765 - acc: 0.6820 - val_loss: 0.6791 - val_acc: 0.6620\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6772 - acc: 0.6920 - val_loss: 0.6798 - val_acc: 0.6660\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6764 - acc: 0.6920 - val_loss: 0.6778 - val_acc: 0.6520\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6776 - acc: 0.6880 - val_loss: 0.6794 - val_acc: 0.6680\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6780 - acc: 0.6860 - val_loss: 0.6787 - val_acc: 0.6640\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6772 - acc: 0.6860 - val_loss: 0.6792 - val_acc: 0.6500\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6774 - acc: 0.6760 - val_loss: 0.6795 - val_acc: 0.6340\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6769 - acc: 0.7040 - val_loss: 0.6806 - val_acc: 0.6520\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.6774 - acc: 0.6940 - val_loss: 0.6788 - val_acc: 0.6420\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6773 - acc: 0.7060 - val_loss: 0.6805 - val_acc: 0.6560\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6766 - acc: 0.6880 - val_loss: 0.6801 - val_acc: 0.6440\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6775 - acc: 0.6900 - val_loss: 0.6789 - val_acc: 0.6420\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6777 - acc: 0.6780 - val_loss: 0.6789 - val_acc: 0.6840\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6775 - acc: 0.7020 - val_loss: 0.6799 - val_acc: 0.6640\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.6780 - acc: 0.6920 - val_loss: 0.6772 - val_acc: 0.6460\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6785 - acc: 0.6840 - val_loss: 0.6810 - val_acc: 0.6460\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6767 - acc: 0.6740 - val_loss: 0.6785 - val_acc: 0.6220\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6767 - acc: 0.6860 - val_loss: 0.6799 - val_acc: 0.6580\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6774 - acc: 0.6900 - val_loss: 0.6788 - val_acc: 0.6580\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6779 - acc: 0.6820 - val_loss: 0.6803 - val_acc: 0.6500\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6772 - acc: 0.7040 - val_loss: 0.6769 - val_acc: 0.6980\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6768 - acc: 0.7080 - val_loss: 0.6786 - val_acc: 0.6860\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6776 - acc: 0.6880 - val_loss: 0.6802 - val_acc: 0.6540\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6775 - acc: 0.6700 - val_loss: 0.6788 - val_acc: 0.6480\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6769 - acc: 0.7020 - val_loss: 0.6789 - val_acc: 0.6620\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6772 - acc: 0.6820 - val_loss: 0.6799 - val_acc: 0.6340\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6772 - acc: 0.6720 - val_loss: 0.6795 - val_acc: 0.6340\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6760 - acc: 0.6820 - val_loss: 0.6792 - val_acc: 0.6580\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.6763 - acc: 0.6920 - val_loss: 0.6794 - val_acc: 0.6520\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6776 - acc: 0.6860 - val_loss: 0.6792 - val_acc: 0.6860\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6765 - acc: 0.7160 - val_loss: 0.6782 - val_acc: 0.6600\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6769 - acc: 0.6920 - val_loss: 0.6793 - val_acc: 0.6500\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6765 - acc: 0.7040 - val_loss: 0.6794 - val_acc: 0.6780\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.6774 - acc: 0.6960 - val_loss: 0.6790 - val_acc: 0.6520\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.6766 - acc: 0.7100 - val_loss: 0.6790 - val_acc: 0.6800\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.6767 - acc: 0.7000 - val_loss: 0.6793 - val_acc: 0.6660\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6770 - acc: 0.6880 - val_loss: 0.6793 - val_acc: 0.6540\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6766 - acc: 0.6820 - val_loss: 0.6803 - val_acc: 0.6420\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6759 - acc: 0.6800 - val_loss: 0.6796 - val_acc: 0.6560\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6769 - acc: 0.6900 - val_loss: 0.6780 - val_acc: 0.6720\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6776 - acc: 0.6900 - val_loss: 0.6796 - val_acc: 0.6500\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.6766 - acc: 0.6940 - val_loss: 0.6779 - val_acc: 0.6740\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.6765 - acc: 0.7020 - val_loss: 0.6785 - val_acc: 0.6680\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.6765 - acc: 0.6880 - val_loss: 0.6786 - val_acc: 0.6840\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6783 - acc: 0.6840 - val_loss: 0.6788 - val_acc: 0.6760\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6775 - acc: 0.7120 - val_loss: 0.6793 - val_acc: 0.6740\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6766 - acc: 0.6880 - val_loss: 0.6781 - val_acc: 0.6620\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6769 - acc: 0.6840 - val_loss: 0.6780 - val_acc: 0.6600\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6785 - acc: 0.6800 - val_loss: 0.6810 - val_acc: 0.6420\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6772 - acc: 0.7000 - val_loss: 0.6778 - val_acc: 0.6720\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 34us/step - loss: 0.6769 - acc: 0.6900 - val_loss: 0.6788 - val_acc: 0.6560\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6768 - acc: 0.7000 - val_loss: 0.6802 - val_acc: 0.6640\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6788 - acc: 0.6900 - val_loss: 0.6773 - val_acc: 0.6860\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6764 - acc: 0.7200 - val_loss: 0.6802 - val_acc: 0.6680\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6771 - acc: 0.6840 - val_loss: 0.6787 - val_acc: 0.6420\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6773 - acc: 0.6880 - val_loss: 0.6781 - val_acc: 0.6700\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6774 - acc: 0.6760 - val_loss: 0.6797 - val_acc: 0.6460\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6775 - acc: 0.6740 - val_loss: 0.6794 - val_acc: 0.6340\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6775 - acc: 0.6920 - val_loss: 0.6787 - val_acc: 0.6740\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6776 - acc: 0.7100 - val_loss: 0.6788 - val_acc: 0.6820\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6768 - acc: 0.7160 - val_loss: 0.6790 - val_acc: 0.6840\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6766 - acc: 0.7120 - val_loss: 0.6790 - val_acc: 0.6420\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 36us/step - loss: 0.6775 - acc: 0.6720 - val_loss: 0.6794 - val_acc: 0.6360\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6767 - acc: 0.6840 - val_loss: 0.6795 - val_acc: 0.6240\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6771 - acc: 0.6840 - val_loss: 0.6801 - val_acc: 0.6580\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6780 - acc: 0.6780 - val_loss: 0.6788 - val_acc: 0.6440\n",
      "500/500 [==============================] - 0s 14us/step\n",
      "500/500 [==============================] - 0s 12us/step\n",
      "Train loss: 0.675, Test loss: 0.679\n",
      "Train metric: 0.682, Test metric: 0.644\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logistic regression with scaled inputs outputs on the regression problem\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=20, activation='sigmoid', kernel_initializer='he_uniform', kernel_regularizer= keras.regularizers.L1L2(l1=0.0, l2=1)))\n",
    "#compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=1)\n",
    "# evaluate the model\n",
    "train_e = model.evaluate(trainX, trainy, verbose=1)\n",
    "test_e = model.evaluate(testX, testy, verbose=1)\n",
    "print('Train loss: %.3f, Test loss: %.3f' % (train_e[0], test_e[0])) \n",
    "print('Train metric: %.3f, Test metric: %.3f' % (train_e[1], test_e[1])) \n",
    "#plot loss during training\n",
    "plt.title('Loss / Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
